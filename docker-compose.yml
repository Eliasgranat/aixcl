services:
  ollama:
    volumes:
      - ollama:/root/.ollama
      - ./scripts/ollama.sh:/entrypoint.sh
    environment:
      - MODELS_BASE=${MODELS_BASE}
      - OLLAMA_HOST=0.0.0.0
      # CPU Threading options - adjust based on your CPU cores
      - OLLAMA_CPU_THREADS=4        # Conservative setting to leave resources for system
      - OLLAMA_GPU_LAYERS=24        # Balanced for 6GB VRAM to avoid OOM
      # Memory and batch size
      - OLLAMA_NUMA=true           # Enable NUMA support
      - OLLAMA_BATCH_SIZE=2048     # Conservative batch size for 1660 Ti
      # Cache settings
      - OLLAMA_MMAP=true           # Enable memory mapping
      - OLLAMA_CACHE_SIZE=3072     # 3GB cache to leave room for system and other apps
    container_name: ollama
    ports:
      - "11434:11434"
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    entrypoint: ["/usr/bin/bash", "/entrypoint.sh"]
    deploy:
      resources:
        limits:
          cpus: '4.0'  # Limit to 4 CPUs (out of 6 available)
          memory: 12G   # Limit to 12 GB of memory
        reservations:
          cpus: '2.0'  # Reserve 2 CPUs
          memory: 6G    # Reserve 6 GB of memory
    networks:
      - ollama-network
    mem_limit: 12G   # Limit to 12 GB of memory
    cpus: '4.0'      # Limit to 4 CPUs (out of 6 available)

  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    volumes:
      - open-webui:/app/backend/data
      - open-webui-data:/app/data
      - ./scripts/openwebui.sh:/app/backend/openwebui.sh
    environment:
      - DATA_DIR=/app/data
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost:5432/${POSTGRES_DATABASE}
      - NVIDIA_VISIBLE_DEVICES=all
      - WEBUI_NAME=AIXCL
      - OLLAMA_BASE_URL=http://localhost:11434
      - OPENWEBUI_EMAIL=${OPENWEBUI_EMAIL}
      - OPENWEBUI_PASSWORD=${OPENWEBUI_PASSWORD}
      # WebUI Performance settings
      - WEBUI_CONCURRENCY=4        # Reduced concurrency for balanced performance
      - WEBUI_THREADS=2            # Conservative thread count
    extra_hosts:
       - "host.docker.internal:host-gateway"
    depends_on:
      - postgres
      - ollama
    network_mode: host
    restart: always
    command: ["/bin/bash", "-c", "chmod +x openwebui.sh && bash openwebui.sh"]
    deploy:

  postgres:
    image: postgres:latest
    container_name: postgres
    environment:
      POSTGRES_USER: $POSTGRES_USER
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
      POSTGRES_DB: $POSTGRES_DATABASE
    volumes:
      - postgres-data:/var/lib/postgresql/data
    network_mode: host
    restart: always
    deploy:

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: $PGADMIN_EMAIL
      PGADMIN_DEFAULT_PASSWORD: $PGADMIN_PASSWORD
      PGADMIN_LISTEN_PORT: 5050
    network_mode: host
    depends_on:
      - postgres
    restart: always

  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: open-webui
    restart: always

volumes:
  ollama:
  open-webui:
  open-webui-data:
  postgres-data:

networks:
  ollama-network:
    driver: bridge
