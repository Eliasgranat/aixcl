services:
  ollama:
    volumes:
      - ollama:/root/.ollama
      - ./scripts/ollama.sh:/entrypoint.sh
    environment:
      - MODELS_BASE=${MODELS_BASE}
      - OLLAMA_HOST=0.0.0.0
      # CPU Threading options
      - OLLAMA_CPU_THREADS=8        # Number of CPU threads to use
      - OLLAMA_GPU_LAYERS=35        # Number of layers to offload to GPU
      # Memory and batch size
      - OLLAMA_NUMA=true           # Enable NUMA support for better memory performance
      - OLLAMA_BATCH_SIZE=4096     # Batch size for processing (default varies by model)
      # Cache settings
      - OLLAMA_MMAP=true           # Enable memory mapping for faster loading
      - OLLAMA_CACHE_SIZE=4096     # Size of the cache in MB
    container_name: ollama
    ports:
      - "11434:11434"
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:latest
    entrypoint: ["/usr/bin/bash", "/entrypoint.sh"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - ollama-network

  open-webui:
    image: ghcr.io/open-webui/open-webui:latest
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - open-webui:/app/backend/data
      - open-webui-data:/app/data
      - ./scripts/openwebui.sh:/app/backend/openwebui.sh
    environment:
      - DATA_DIR=/app/data
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@localhost:5432/${POSTGRES_DATABASE}
      - NVIDIA_VISIBLE_DEVICES=all
      - WEBUI_NAME=AIXCL
      - OLLAMA_BASE_URL=http://localhost:11434
      - OPENWEBUI_EMAIL=${OPENWEBUI_EMAIL}
      - OPENWEBUI_PASSWORD=${OPENWEBUI_PASSWORD}
      # WebUI Performance settings
      - WEBUI_CONCURRENCY=10       # Number of worker processes
      - WEBUI_THREADS=4            # Number of threads per worker
    extra_hosts:
       - "host.docker.internal:host-gateway"
    depends_on:
      - postgres
      - ollama
    network_mode: host
    restart: always
    command: ["/bin/bash", "-c", "chmod +x openwebui.sh && bash openwebui.sh"]
    deploy:
      resources:
        limits:
          cpus: '6'
          memory: 24G
        reservations:
          cpus: '2'
          memory: 4G

  postgres:
    image: postgres:latest
    container_name: postgres
    environment:
      POSTGRES_USER: $POSTGRES_USER
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD
      POSTGRES_DB: $POSTGRES_DATABASE
    volumes:
      - postgres-data:/var/lib/postgresql/data
    network_mode: host
    restart: always

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: $PGADMIN_EMAIL
      PGADMIN_DEFAULT_PASSWORD: $PGADMIN_PASSWORD
      PGADMIN_LISTEN_PORT: 5050
    network_mode: host
    depends_on:
      - postgres
    restart: always

  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: open-webui
    restart: always

volumes:
  ollama:
  open-webui:
  open-webui-data:
  postgres-data:

networks:
  ollama-network:
    driver: bridge
